#!/usr/bin/env python3

import argparse
import socket
import ssl

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443

class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password

    def run(self):
        request = "GET / HTTP/1.0\r\n\r\n"

        print("Request to %s:%d" % (self.server, self.port))
        print(request)
        mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        mysocket = ssl.wrap_socket(mysocket)
        mysocket.connect((self.server, self.port))
        mysocket.send(request.encode('ascii'))

        data = mysocket.recv(99999)
        print("Response:\n%s" % data.decode('ascii'))

        request2 = "GET /accounts/login/ HTTP/1.0\r\n\r\n"
        #mysocket.connect((self.server, self.port))
        mysocket.send(request2.encode('ascii'))
        data2 = mysocket.recv(99999)
        print(data2)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
