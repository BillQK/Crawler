#!/usr/bin/env python3

import argparse
import socket
import ssl
import re
from html.parser import HTMLParser

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443

#array for storing the outgoing fakebook links with each person
links = []
#array for storing the outgoing fakebook friends list for each person
friendlinks = []
#array for storing the flags
flags = set()

#HTML Parser class used for parsing HTML messages in this case mainly used for determining the flags
#and valid fakebook friends, and fakebook friends lists
class MyHTMLParser(HTMLParser):

    def handle_starttag(self, tag, attrs):
        if(tag == "a"):
            for name, val in attrs:
                if name == "href":
                    if("fakebook" in val):
                        if("friends" in val):
                            friendlinks.append(val)
                        else:
                            links.append(val)                       


    def handle_data(self, data):
        if("FLAG" in data):
            print(data[6:len(data)])
            flags.add(data)

        

class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        self.csrf = None
        self.sessionid = None
        self.middleware = ""
        self.testlist = []
        self.parser = MyHTMLParser()
        self.visited = set()
        self.visitedpages = set()
        self.pagequeue = []
        self.queue = []
        #count for keeping track of when we need to rebuild the socket
        self.count = 0
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket = ssl.wrap_socket(self.socket)
        self.socket.connect((self.server, self.port)) 


    def run(self):
        self.loginProcess()
        self.DFS()

    #implements a similar approach to DFS to traverse all the pages of the friend nodes, for reach profile in fakebook,
    #we check to see if they contain any flags, then add all their unseen friends to queue, and check them later     
    def DFS(self):
        while len(self.queue) > 0:
            self.count = self.count + 1
            if(self.count % 100 == 0):
                self.BuildSocket()
                continue

            currentfriend = self.queue[0]
            req = self.BuildGetRequest(currentfriend, True)

            #try except for when the server may get backed up and a socket may fail to connect,
            #just re try again
            try:
                msg = self.BuildNewSocket(req)
            except:
                continue    

            if("HTTP/1.1 503" in msg):
                #we continue with this loop to have our method retransmit the message
                continue

            elif("HTTP/1.1 4" in msg or "HTTP/1.1 3" in msg):
                self.queue.remove(currentfriend)
                self.visited.add(currentfriend)
                continue

            else:
                #clear our previous entries in our link lists
                friendlinks.clear()
                self.parser.feed(msg)

                if(len(flags) == 5):
                    return

                #if its passed the previous checks successfully we can remove the item from our queue and add it to visited
                self.queue.remove(currentfriend)
                self.visited.add(currentfriend)

                self.pagequeue = friendlinks.copy()

                #get all the friend links we need to visit next
                while len(self.pagequeue) > 0:
                    friendpage = self.pagequeue[0]

                    #then create get request for the next page, to add all those links to what we need to explore
                    nextpagereq = self.BuildGetRequest(friendpage, True)

                    try:
                        nextpage = self.BuildNewSocket(nextpagereq)
                    except:
                        continue    

                    if("HTTP/1.1 503" in nextpage):
                        #when its a 500 error we try to retansmit and dont add anything to visited 
                        continue

                    elif("HTTP/1.1 4" in nextpage or "HTTP/1.1 3" in nextpage):
                        #when its a invalid website or a server redirection, should do nothing
                        self.pagequeue.remove(friendpage)
                        self.visitedpages.add(friendpage)
                        continue

                    else:
                        self.pagequeue.remove(friendpage)
                        self.visitedpages.add(friendpage)

                        self.parser.feed(nextpage)

                        #checks the links our html parser found for those unvisited and not in queue
                        for i in links:
                            if(i not in self.visited and i not in self.queue):
                                self.queue.append(i)

                        #reset the links list so we can be prepared for the next website        
                        links.clear()

                        #for each item in our friends list check if there is a page that has not been explored yet
                        newqueue = []
                        for i in friendlinks:
                            if(i not in self.visitedpages):
                                newqueue.append(i)

                        self.pagequeue = newqueue.copy()
                                               
    #finds and stores the necessary cookies, session tokens, and crsf middleware tokens      
    def findcookievariables(self, edata):
        datalist = edata.split()
        for i in datalist:
            if "csrftoken" in i:
                self.csrf= i[:len(i) -1]
            elif "sessionid" in i:
                self.sessionid = i[:len(i) - 1]
            elif "value" in i:
                self.testlist.append(i)

        #crafts the middleware token, to be the specific index
        self.middleware = self.testlist[0]
        self.middleware = self.middleware[:len(self.middleware) - 2]
        self.middleware = self.middleware[7 : len(self.middleware)]

    #rebuild the socket with each request
    def BuildGetRequest(self, url, cookies):
        request = "GET " + url + " HTTP/1.1\r\nHost: " + self.server + "\r\nConnection: keep-alive\r\n" 
        if(cookies):
            cookiestring = "Cookie: " + self.csrf + "; " + self.sessionid + "\r\n"  
            request = request + cookiestring

        request = request + "\r\n"
        return request

    def BuildSocket(self):
        self.socket.close()
        mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        mysocket = ssl.wrap_socket(mysocket)
        mysocket.connect((self.server, self.port))
        self.socket = mysocket         

    #since we specify connection: close, we have to rebuild a socket with each request
    def BuildNewSocket(self, httpR):
        self.socket.send(httpR.encode('ascii'))
        contentlength = 0
        
        #receiving loop to properly recve all information from an HTTP response
        while True:
            chunks = ""
            while "\r\n\r\n" not in chunks:
                chunk = self.socket.recv(4).decode('ascii')
                chunks = chunks + chunk

            headersplit = chunks.split("\r\n")
            for i in headersplit:
                if("Content-Length:" in i):
                    contentlength = int(i[16: len(i)]) 

            msg = self.socket.recv(contentlength).decode('ascii')
            totalmessage = chunks + msg    
            return totalmessage


    #Builds a log in request, using the cookies that we have found,
    def buildloginpostr(self):
        payload  = "username=" + self.username + "&password=" + self.password + "&csrfmiddlewaretoken="+ self.middleware + "&next=%2Ffakebook%2F\r\n\r\n"
        Contentlength = len(payload)
        prequest = "POST /accounts/login/ HTTP/1.1\r\nHost: " + self.server + "\r\n" + "Cookie: "+ self.csrf + "; " + self.sessionid + "\r\n" + "Content-Type: application/x-www-form-urlencoded\r\n" + "Connection: keep-alive\r\n" + "Content-length: " + str(Contentlength) + "\r\n" + "Referrer: https://" + self.server + "/accounts/login/?next=/fakebook/\r\n\r\n"  
        post = prequest + payload
        return post

    #does the entire log in process for the server
    def loginProcess(self):
        intialconnect = "/"
        req = self.BuildGetRequest(intialconnect, False)
        msg = self.BuildNewSocket(req)

        #gets to the log in 
        nextpage = "/accounts/login/?next=/fakebook/"
        req = self.BuildGetRequest(nextpage, False)
        msg = self.BuildNewSocket(req)
        self.findcookievariables(msg)

        #builds the log in post rquest
        loginpost = self.buildloginpostr()
        msg = self.BuildNewSocket(loginpost)
        self.findcookievariables(msg)

        #continues the get request to the home page
        homepage = "/fakebook/"
        req = self.BuildGetRequest(homepage, True)
        msg = self.BuildNewSocket(req)

        self.parser.feed(msg)
        self.queue = links.copy()
        links.clear()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
